# PRODPLAN Streamlit UI: –ü—Ä–æ—Å–º–æ—Ç—Ä "–ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞" –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –ë–î
# –ó–∞–ø—É—Å–∫: streamlit run src/ui.py

import datetime as dt
import json
import sqlite3
from pathlib import Path
import pandas as pd
import streamlit as st
from dataclasses import asdict
import time
import subprocess
import shutil
from urllib import request as _urlreq, error as _urlerr
import urllib.parse as _urlparse
import numpy as np
import hashlib
from concurrent.futures import ThreadPoolExecutor, as_completed

from src.planner import generate_plan_dataframe
from src.database import get_connection, init_database
from src.bom_calculator import get_root_products, explode_bom_for_root
from src.odata_client import OData1CClient


# ============================
# LLM (Ollama) health-check & autostart
# ============================
OLLAMA_BASE_URL = "http://localhost:11434"
OLLAMA_HEALTH_PATH = "/api/tags"

def _ollama_is_healthy(timeout: float = 1.5) -> bool:
    try:
        req = _urlreq.Request(f"{OLLAMA_BASE_URL}{OLLAMA_HEALTH_PATH}")
        with _urlreq.urlopen(req, timeout=timeout) as resp:
            code = getattr(resp, "status", None) or resp.getcode()
            return 200 <= int(code) < 300
    except Exception:
        return False

def _start_ollama_background() -> bool:
    """
    –ü—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å 'ollama serve' –≤ —Ñ–æ–Ω–µ (Windows, detached).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ —Å—Ç–∞—Ä—Ç–æ–≤–∞–ª–∞ –±–µ–∑ –∏—Å–∫–ª—é—á–µ–Ω–∏–π.
    """
    exe = shutil.which("ollama")
    if not exe:
        return False
    try:
        # –ü–æ–ø—ã—Ç–∫–∞ –¥–µ—Ç–∞—á–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å –Ω–∞ Windows; –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–≥–Ω–æ—Ä–∏—Ä—É—é—Ç—Å—è –Ω–∞ POSIX
        creationflags = 0
        try:
            creationflags = getattr(subprocess, "DETACHED_PROCESS", 0) | getattr(subprocess, "CREATE_NEW_PROCESS_GROUP", 0)
        except Exception:
            creationflags = 0
        subprocess.Popen(
            [exe, "serve"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
            stdin=subprocess.DEVNULL,
            creationflags=creationflags,
            close_fds=True,
            shell=False,
        )
        return True
    except Exception:
        return False

def ensure_ollama_running(max_wait_seconds: float = 30.0, poll_interval: float = 1.0):
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å Ollama –∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –ø—ã—Ç–∞–µ—Ç—Å—è –∑–∞–ø—É—Å—Ç–∏—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂ (ok: bool, message: str)
    """
    if _ollama_is_healthy():
        return True, "Ollama —É–∂–µ –æ—Ç–≤–µ—á–∞–µ—Ç"
    started = _start_ollama_background()
    if not started:
        return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å 'ollama serve' (–∏—Å–ø–æ–ª–Ω—è–µ–º—ã–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –æ—Ç–∫–∞–∑ –∑–∞–ø—É—Å–∫–∞)"
    deadline = time.time() + float(max_wait_seconds)
    while time.time() < deadline:
        if _ollama_is_healthy():
            return True, "Ollama –∑–∞–ø—É—â–µ–Ω–∞ –∏ –æ—Ç–≤–µ—á–∞–µ—Ç"
        time.sleep(float(poll_interval))
    return False, f"Ollama –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª–∞ –∑–∞ {int(max_wait_seconds)}—Å –Ω–∞ {OLLAMA_HEALTH_PATH}"

# ============================
# –õ–æ–∫–∞–ª—å–Ω—ã–π –∏–Ω–¥–µ–∫—Å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã (OData 1–° ‚Üí —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —á–µ—Ä–µ–∑ Ollama)
# ============================
OLLAMA_EMBED_MODEL = "nomic-embed-text"
NOMEN_INDEX_PATH = Path("output/nomenclature_index.json")

def _ensure_output_dir():
    try:
        Path("output").mkdir(parents=True, exist_ok=True)
    except Exception:
        pass

def _read_nomen_index() -> dict:
    try:
        if NOMEN_INDEX_PATH.exists():
            with NOMEN_INDEX_PATH.open("r", encoding="utf-8") as f:
                return json.load(f) or {}
    except Exception:
        return {}
    return {}

def _write_nomen_index(data: dict) -> None:
    try:
        _ensure_output_dir()
        with NOMEN_INDEX_PATH.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def _ollama_embed_text(text: str, timeout: float = 60.0) -> list[float] | None:
    try:
        url = f"{OLLAMA_BASE_URL}/api/embeddings"
        payload = json.dumps({"model": OLLAMA_EMBED_MODEL, "prompt": str(text)}).encode("utf-8")
        req = _urlreq.Request(url, data=payload, method="POST")
        req.add_header("Content-Type", "application/json")
        with _urlreq.urlopen(req, timeout=timeout) as resp:
            raw = resp.read().decode("utf-8", errors="ignore")
            data = json.loads(raw)
            if isinstance(data, dict):
                if "embedding" in data and isinstance(data["embedding"], list):
                    return [float(x) for x in data["embedding"]]
                if "data" in data and isinstance(data["data"], list) and data["data"]:
                    emb = data["data"][0].get("embedding")
                    if isinstance(emb, list):
                        return [float(x) for x in emb]
    except Exception:
        return None
    return None

def _extract_count(resp: dict) -> int | None:
    """
    –ü–æ–ø—ã—Ç–∫–∞ –∏–∑–≤–ª–µ—á—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –∏–∑ –æ—Ç–≤–µ—Ç–∞ OData.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è –∫–ª—é—á–∏ –≤–∏–¥–∞ '@odata.count', 'odata.count', 'Count', 'count'.
    """
    if not isinstance(resp, dict):
        return None
    for k in ("@odata.count", "odata.count", "Count", "count"):
        if k in resp:
            try:
                return int(resp.get(k))
            except Exception:
                continue
    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–µ—Ä–≤–µ—Ä—ã –∫–ª–∞–¥—É—Ç count –≤ metadata-–ø–æ–ª–µ ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
    return None

def _try_get_nomenclature_count() -> int | None:
    """
    –ü–æ–ª—É—á–∏—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞ —á–µ—Ä–µ–∑ OData ($count=true/$inlinecount).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ —Å–µ—Ä–≤–µ—Ä –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø–æ–¥—Å—á—ë—Ç.
    """
    cfg = _load_odata_config()
    base_url = (cfg.get("base_url") or "").strip()
    username = (cfg.get("username") or "").strip() or None
    password = (cfg.get("password") or "").strip() or None
    if not base_url:
        return None
    client = OData1CClient(base_url=base_url, username=username, password=password, token=None)
    # –ü–æ–ø—ã—Ç–∫–∞ 1: $count=true, $top=0
    try:
        resp = client._make_request("Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", {"$count": "true", "$top": 0})
        cnt = _extract_count(resp)
        if isinstance(cnt, int) and cnt >= 0:
            return cnt
    except Exception:
        pass
    # –ü–æ–ø—ã—Ç–∫–∞ 2: $inlinecount=allpages, $top=1 (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å —Å–æ —Å—Ç–∞—Ä—ã–º–∏ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è–º–∏)
    try:
        resp2 = client._make_request("Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", {"$inlinecount": "allpages", "$top": 1})
        cnt = _extract_count(resp2)
        if isinstance(cnt, int) and cnt >= 0:
            return cnt
    except Exception:
        pass
    return None

def _fetch_nomenclature_from_1c(limit: int = 30000, on_progress=None) -> tuple[list[dict], int | None]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –∏–∑ 1–° OData: –ø–æ–ª—è Code, Description, –ê—Ä—Ç–∏–∫—É–ª.
    –ß–∏—Ç–∞–µ—Ç –±–∞–∑–æ–≤—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config/odata_config.json.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Å–ø–∏—Å–æ–∫_–∑–∞–ø–∏—Å–µ–π, total_count_–∏–ª–∏_None). –ö–æ–ª–ª–±–µ–∫ on_progress —Å–æ–æ–±—â–∞–µ—Ç —Ö–æ–¥ –∑–∞–≥—Ä—É–∑–∫–∏.
    """
    cfg = _load_odata_config()
    base_url = (cfg.get("base_url") or "").strip()
    username = (cfg.get("username") or "").strip() or None
    password = (cfg.get("password") or "").strip() or None
    if not base_url:
        return [], None
    client = OData1CClient(base_url=base_url, username=username, password=password, token=None)

    total_count = _try_get_nomenclature_count()
    if isinstance(total_count, int) and total_count >= 0:
        total_count = min(total_count, int(limit))
    else:
        total_count = None

    out: list[dict] = []
    top = 1000
    skip = 0
    max_pages = max(1, int(limit // top) + 2)
    pages = 0
    while len(out) < limit and pages < max_pages:
        params = {
            "$select": "Code,Description,–ê—Ä—Ç–∏–∫—É–ª",
            "$top": top,
            "$skip": skip,
        }
        try:
            resp = client._make_request("Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞", params)
        except Exception:
            break
        rows = []
        if isinstance(resp, dict) and isinstance(resp.get("value"), list):
            rows = resp.get("value", [])
        elif resp:
            rows = [resp]
        if not rows:
            break
        last_name = ""
        last_code = ""
        for r in rows:
            try:
                code = str(r.get("Code") or "").strip()
                name = str(r.get("Description") or "").strip()
                article = str(r.get("–ê—Ä—Ç–∏–∫—É–ª") or "").strip()
                if code or name or article:
                    out.append({"code": code, "name": name, "article": article})
                    last_name = name
                    last_code = code
                    if len(out) >= limit:
                        break
            except Exception:
                continue
        # –ü—Ä–æ–≥—Ä–µ—Å—Å –ø–æ –∑–∞–≥—Ä—É–∑–∫–µ –∏–∑ OData (–ø–æ—Å—Ç—Ä–∞–Ω–∏—á–Ω–æ)
        if callable(on_progress):
            try:
                on_progress(len(out), total_count, {"phase": "fetch", "last_name": last_name, "last_code": last_code})
            except Exception:
                pass
        if len(rows) < top:
            break
        skip += len(rows)
        pages += 1
    return out, total_count
def _compute_item_hash(name: str, article: str, code: str) -> str:
    """
    –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∫–∞—Ä—Ç–æ—á–∫–∏ –¥–ª—è –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏.
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–≥–∏—Å—Ç—Ä –∏ –ø—Ä–æ–±–µ–ª—ã.
    """
    def norm(x: str) -> str:
        return " ".join((x or "").strip().split()).upper()
    payload = f"{norm(name)}|{norm(article)}|{norm(code)}"
    return hashlib.sha1(payload.encode("utf-8")).hexdigest()


def _embed_items_parallel(items_to_embed: list[dict], max_workers: int, on_progress, total_embed: int) -> tuple[list[dict], int]:
    """
    –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π —Ä–∞—Å—á—ë—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è —Å–ø–∏—Å–∫–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤.
    items_to_embed: [{code,name,article,hash}]
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (—Å–ø–∏—Å–æ–∫_—É—Å–ø–µ—à–Ω—ã—Ö_—ç–ª–µ–º–µ–Ω—Ç–æ–≤, failed_count).
    """
    results: list[dict] = []
    failed = 0
    processed = 0
    # –í—ã–ø–æ–ª–Ω—è–µ–º –∑–∞–ø—Ä–æ—Å—ã –≤ –ø—É–ª–µ –ø–æ—Ç–æ–∫–æ–≤
    with ThreadPoolExecutor(max_workers=max(1, int(max_workers))) as ex:
        futures = {}
        for it in items_to_embed:
            txt = " | ".join([s for s in [it.get("name") or "", it.get("article") or "", it.get("code") or ""] if s])
            futures[ex.submit(_ollama_embed_text, txt)] = it
        for fut in as_completed(futures):
            it = futures[fut]
            vec = None
            try:
                vec = fut.result()
            except Exception:
                vec = None
            if vec is not None:
                results.append({
                    "code": it.get("code") or "",
                    "name": it.get("name") or "",
                    "article": it.get("article") or "",
                    "vector": vec,
                    "hash": it.get("hash") or "",
                })
            else:
                failed += 1
            processed += 1
            if callable(on_progress):
                try:
                    on_progress(processed, total_embed, {"phase": "embed", "name": it.get("name") or "", "article": it.get("article") or "", "code": it.get("code") or ""})
                except Exception:
                    pass
    return results, failed

def ensure_llama_index_daily(on_progress=None, max_workers: int = 4) -> tuple[bool, str, bool]:
    """
    –ï–∂–µ—Å—É—Ç–æ—á–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –∏–Ω–¥–µ–∫—Å–∞ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã —Å –∏–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–π –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–µ–π.
    on_progress(processed:int, total:int|None, info:dict) ‚Äî –∫–æ–ª–ª–±–µ–∫ –¥–ª—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (ok, message, skipped).
    """
    started_at = time.time()

    # –°—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—à–ª—ã–π –∏–Ω–¥–µ–∫—Å
    idx = _read_nomen_index()
    last_ts = None
    try:
        last_ts = idx.get("meta", {}).get("last_indexed_at")
    except Exception:
        last_ts = None

    now = dt.datetime.utcnow()
    if last_ts:
        try:
            prev = dt.datetime.fromisoformat(str(last_ts).replace("Z", ""))
            if (now - prev).total_seconds() < 24 * 3600:
                return True, f"–ò–Ω–¥–µ–∫—Å –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è (–ø–æ—Å–ª–µ–¥–Ω–∏–π –∑–∞–ø—É—Å–∫: {prev.isoformat()}Z)", True
        except Exception:
            pass

    if not _ollama_is_healthy():
        return False, "Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤", False

    # 1) –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Ç–∞–ª–æ–≥ –∏–∑ 1–° (—Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º)
    items, total_count = _fetch_nomenclature_from_1c(limit=30000, on_progress=on_progress)
    if not items:
        return False, "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –∏–∑ 1–°", False

    # 2) –ì–æ—Ç–æ–≤–∏–º map –ø–æ —Å—Ç–∞—Ä–æ–º—É –∏–Ω–¥–µ–∫—Å—É
    old_items = []
    try:
        old_items = idx.get("items") or []
    except Exception:
        old_items = []
    old_by_code: dict[str, dict] = {}
    for e in old_items:
        try:
            code = str(e.get("code") or "")
            if code:
                old_by_code[code] = e
        except Exception:
            continue

    # 3) –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ –¥–ª—è –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è/–ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏
    new_by_code: dict[str, dict] = {}
    to_embed: list[dict] = []
    reused = 0
    for it in items:
        code = str(it.get("code") or "")
        name = str(it.get("name") or "")
        article = str(it.get("article") or "")
        if not code and not name and not article:
            continue
        h = _compute_item_hash(name, article, code)
        rec = {"code": code, "name": name, "article": article, "hash": h}
        old = old_by_code.get(code)
        if old and str(old.get("hash") or "") == h and isinstance(old.get("vector"), list):
            # –ù–µ –∏–∑–º–µ–Ω–∏–ª–æ—Å—å ‚Äî –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä
            rec["vector"] = old.get("vector")
            reused += 1
        else:
            # –¢—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ—Å—á—ë—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            to_embed.append(rec)
        new_by_code[code] = rec

    removed_codes = [c for c in old_by_code.keys() if c not in new_by_code]

    # 4) –ü–µ—Ä–µ—Å—á–∏—Ç—ã–≤–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –∏–∑–º–µ–Ω—ë–Ω–Ω—ã—Ö/–Ω–æ–≤—ã—Ö
    embedded: list[dict] = []
    failed = 0
    total_embed = len(to_embed)
    if total_embed > 0:
        embedded, failed = _embed_items_parallel(to_embed, max_workers=max_workers, on_progress=on_progress, total_embed=total_embed)

    # 5) –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Å–ø–∏—Å–æ–∫
    emb_by_code = {e["code"]: e for e in embedded}
    final_items: list[dict] = []
    for code, rec in new_by_code.items():
        if "vector" in rec and isinstance(rec["vector"], list):
            final_items.append({"code": rec["code"], "name": rec["name"], "article": rec["article"], "vector": rec["vector"], "hash": rec["hash"]})
        else:
            emb = emb_by_code.get(code)
            if emb and isinstance(emb.get("vector"), list):
                final_items.append({"code": rec["code"], "name": rec["name"], "article": rec["article"], "vector": emb["vector"], "hash": rec["hash"]})
            # –ò–Ω–∞—á–µ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –±–µ–∑–≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –∑–∞–ø–∏—Å–∏ (–Ω–µ –ø–æ–ø–∞–¥—É—Ç –≤ –∏–Ω–¥–µ–∫—Å)

    if not final_items:
        return False, "–≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –Ω–µ –ø–æ–ª—É—á–µ–Ω—ã (–≤–æ–∑–º–æ–∂–Ω–æ, –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞)", False

    # 6) –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏–Ω–¥–µ–∫—Å –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    duration = int(time.time() - started_at)
    data = {
        "meta": {
            "model": OLLAMA_EMBED_MODEL,
            "last_indexed_at": now.isoformat() + "Z",
            "count": len(final_items),
            "stats": {
                "total_catalog": len(items),
                "unchanged_reused": reused,
                "reembedded": len(embedded),
                "failed": int(failed),
                "removed": len(removed_codes),
                "duration_sec": duration,
                "total_count_hint": total_count if isinstance(total_count, int) else None,
                "max_workers": int(max_workers),
            },
        },
        "items": final_items,
    }
    _write_nomen_index(data)

    msg = f"–ò–Ω–¥–µ–∫—Å –≥–æ—Ç–æ–≤: –≤—Å–µ–≥–æ={len(items)}, –ø–µ—Ä–µ–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ={reused}, –ø–µ—Ä–µ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–æ={len(embedded)}, —É–¥–∞–ª–µ–Ω–æ={len(removed_codes)}, –æ—à–∏–±–∫–∏={failed}, {duration}—Å"
    return True, msg, False

def _llama_search_nomenclature(query: str, limit: int = 10) -> list[dict]:
    """
    –õ–æ–∫–∞–ª—å–Ω—ã–π —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –∏–Ω–¥–µ–∫—Å—É: —ç–º–±–µ–¥–¥–∏–Ω–≥ –∑–∞–ø—Ä–æ—Å–∞ ‚Üí –∫–æ—Å–∏–Ω—É—Å–Ω–∞—è –±–ª–∏–∑–æ—Å—Ç—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç [{name, code}] –¥–ª—è UI. –§–æ–ª–±—ç–∫ –Ω–∞ –ë–î –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –≤—ã—à–µ –ø–æ —Å—Ç–µ–∫—É.
    """
    q = (query or "").strip()
    if len(q) < 2:
        return []
    idx = _read_nomen_index()
    items = idx.get("items") if isinstance(idx, dict) else None
    if not items:
        return []

    qvec = _ollama_embed_text(q)
    if not qvec:
        return []

    try:
        M = np.array([it.get("vector", []) for it in items], dtype=np.float32)
        qv = np.array(qvec, dtype=np.float32)
        if M.ndim != 2 or qv.ndim != 1 or M.shape[1] != qv.shape[0]:
            return []
        denom = (np.linalg.norm(M, axis=1) + 1e-9) * (np.linalg.norm(qv) + 1e-9)
        sims = (M @ qv) / denom
        top_idx = np.argsort(-sims)[:max(1, limit)]
        out: list[dict] = []
        for i in top_idx:
            try:
                it = items[int(i)]
                name = str(it.get("name") or "")
                code = str(it.get("code") or "")
                out.append({"name": name, "code": code})
            except Exception:
                continue
        return out
    except Exception:
        return []

def _db_search_nomenclature(query: str, limit: int = 10) -> list[dict]:
    like = f"%{query}%"
    with get_connection(None) as conn:
        try:
            rows = conn.execute(
                "SELECT item_name, item_code FROM items WHERE item_name LIKE ? OR item_code LIKE ? LIMIT 20",
                (like, like),
            ).fetchall()
        except Exception:
            return []
    out: list[dict] = []
    for r in rows:
        name = str(r[0] or "")
        code_v = str(r[1] or "")
        if not code_v:
            continue
        out.append({"name": name, "code": code_v})
        if len(out) >= limit:
            break
    return out

def _ensure_item_and_add_to_roots(code: str, name: str = "") -> None:
    code = (code or "").strip()
    name = (name or "").strip() or code
    if not code:
        raise ValueError("–ü—É—Å—Ç–æ–π –∞—Ä—Ç–∏–∫—É–ª")
    with get_connection(None) as conn:
        row = conn.execute("SELECT item_id FROM items WHERE item_code = ?", (code,)).fetchone()
        if row:
            item_id = int(row[0])
        else:
            cur = conn.execute(
                "INSERT INTO items (item_code, item_name) VALUES (?, ?)",
                (code, name),
            )
            item_id = int(cur.lastrowid)
        conn.execute("INSERT OR IGNORE INTO root_products (item_id) VALUES (?)", (item_id,))
        conn.commit()

def _delete_items_from_plan_by_codes(codes: list[str]) -> None:
    if not codes:
        return
    codes = [str(c).strip() for c in codes if str(c).strip()]
    if not codes:
        return
    placeholders = ",".join("?" for _ in codes)
    with get_connection(None) as conn:
        rows = conn.execute(f"SELECT item_id FROM items WHERE item_code IN ({placeholders})", codes).fetchall()
        item_ids = [int(r[0]) for r in rows]
        if not item_ids:
            return
        ph2 = ",".join("?" for _ in item_ids)
        conn.execute(f"DELETE FROM root_products WHERE item_id IN ({ph2})", item_ids)
        conn.execute(f"DELETE FROM production_plan_entries WHERE item_id IN ({ph2})", item_ids)
        conn.commit()

def _is_date_header(col: str) -> bool:
    # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –¥–∞—Ç —Ñ–æ—Ä–º–∞—Ç–∞ dd.mm.yy (—Ä–æ–≤–Ω–æ 8 —Å–∏–º–≤–æ–ª–æ–≤: 10.09.25)
    if not isinstance(col, str) or len(col) != 8:
        return False
    if col[2] != "." or col[5] != ".":
        return False
    try:
        dt.datetime.strptime(col, "%d.%m.%y")
        return True
    except Exception:
        return False


def _style_weekends(df: pd.DataFrame):
    # –ü–æ–¥—Å–≤–µ—Ç–∫–∞ –≤—ã—Ö–æ–¥–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ —Å–µ—Ä—ã–º —Ñ–æ–Ω–æ–º
    styles = pd.DataFrame("", index=df.index, columns=df.columns)
    for col in df.columns:
        if _is_date_header(col):
            d = dt.datetime.strptime(col, "%d.%m.%y").date()
            if d.weekday() >= 5:  # 5=–°–±, 6=–í—Å
                styles[col] = "background-color: #E6E6E6"
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É —Å—Ç–∏–ª–µ–π —Ç–æ–π –∂–µ —Ñ–æ—Ä–º—ã
    return styles


def _get_last_stock_sync_at() -> str | None:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞—Ç—É/–≤—Ä–µ–º—è –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤.
    –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
      1) MAX(recorded_at) –∏–∑ stock_history (–µ—Å–ª–∏ –≤–∫–ª—é—á–∞–ª–∏ sync —Å –∏—Å—Ç–æ—Ä–∏–µ–π)
      2) MAX(updated_at) –∏–∑ items, –≥–¥–µ stock_qty IS NOT NULL
    """
    with get_connection(None) as conn:
        # 1) –ò—Å—Ç–æ—Ä–∏—è –æ—Å—Ç–∞—Ç–∫–æ–≤
        try:
            row = conn.execute("SELECT MAX(recorded_at) FROM stock_history").fetchone()
            if row and row[0]:
                return str(row[0])
        except Exception:
            pass
        # 2) –ü–æ –∫–∞—Ä—Ç–æ—á–∫–∞–º
        try:
            row2 = conn.execute("SELECT MAX(updated_at) FROM items WHERE stock_qty IS NOT NULL").fetchone()
            if row2 and row2[0]:
                return str(row2[0])
        except Exception:
            pass
    return None

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è OData: —á—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å
CONFIG_DIR = Path("config")
CONFIG_PATH = CONFIG_DIR / "odata_config.json"

def _load_odata_config() -> dict:
    try:
        if CONFIG_PATH.exists():
            import json as _json
            with CONFIG_PATH.open("r", encoding="utf-8") as f:
                data = _json.load(f)
                if isinstance(data, dict):
                    return data
    except Exception:
        pass
    return {}

def _save_odata_config(cfg: dict) -> None:
    try:
        CONFIG_DIR.mkdir(parents=True, exist_ok=True)
        with CONFIG_PATH.open("w", encoding="utf-8") as f:
            json.dump(cfg, f, ensure_ascii=False, indent=2)
    except Exception:
        # –í UI –ø–æ–∫–∞–∂–µ–º –æ—à–∏–±–∫—É –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        pass

def _mask_secret(value: str | None) -> str:
    return "‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢‚Ä¢" if value else ""

def _format_prefixes(prefixes: dict | None) -> str:
    """
    –ü—Ä–µ–≤—Ä–∞—â–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –ø—Ä–µ—Ñ–∏–∫—Å–æ–≤ –≤–∏–¥–∞ {"item_code": ["AB","CD"]} –≤ –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç:
      item_code=AB,CD
    """
    if not isinstance(prefixes, dict):
        return ""
    lines: list[str] = []
    for k, arr in prefixes.items():
        if isinstance(arr, (list, tuple)):
            vals = [str(x).strip() for x in arr if str(x).strip()]
            lines.append(f"{k}=" + ",".join(vals))
    return "\n".join(lines)

def _parse_prefixes(text: str) -> dict[str, list[str]]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ–º –º–Ω–æ–≥–æ—Å—Ç—Ä–æ—á–Ω—ã–π —Ç–µ–∫—Å—Ç —Ñ–æ—Ä–º–∞—Ç–∞:
      key=pre1,pre2
      another=AA,BB
    -> {"key":["pre1","pre2"], "another":["AA","BB"]}
    –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏, –Ω–∞—á–∏–Ω–∞—é—â–∏–µ—Å—è —Å #.
    """
    out: dict[str, list[str]] = {}
    if not text:
        return out
    for raw in text.splitlines():
        line = (raw or "").strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        k, v = line.split("=", 1)
        key = k.strip()
        vals = [p.strip() for p in v.split(",") if p.strip()]
        if key:
            out[key] = vals
    return out


def main():
    st.set_page_config(page_title="PRODPLAN ‚Äî –ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", layout="wide")
    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã (–≤–∫–ª—é—á–∞—è production_areas) —Å–æ–∑–¥–∞–Ω—ã
    try:
        init_database()
    except Exception:
        pass
     
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∞–≤—Ç–æ–∑–∞–ø—É—Å–∫ Ollama (–ª–æ–∫–∞–ª—å–Ω—ã–π LLM)
    if "ollama_check_done" not in st.session_state:
        try:
            with st.spinner("–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–ø—É—Å–∫ Ollama‚Ä¶"):
                ok, msg = ensure_ollama_running(max_wait_seconds=30.0, poll_interval=1.0)
            if ok:
                st.success(f"LLM: {msg}")
            else:
                st.warning(f"LLM: {msg}")
            st.session_state["ollama_check_done"] = True
            st.session_state["ollama_check_status"] = "ok" if ok else "warn"
            st.session_state["ollama_check_message"] = msg
        except Exception as _e:
            st.warning(f"LLM: —Å–±–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏/–∑–∞–ø—É—Å–∫–∞: {_e}")
            st.session_state["ollama_check_done"] = True
            st.session_state["ollama_check_status"] = "warn"
            st.session_state["ollama_check_message"] = str(_e)
    else:
        _status = st.session_state.get("ollama_check_status", "")
        _msg = st.session_state.get("ollama_check_message", "")
        if _status == "ok":
            st.caption(f"LLM –≥–æ—Ç–æ–≤: {_msg}")
        else:
            st.caption(f"LLM –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: {_msg}")
    
    # –ï–∂–µ—Å—É—Ç–æ—á–Ω–∞—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã (—á–µ—Ä–µ–∑ Ollama) ‚Äî —Å –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–º –≤ UI
    if "llama_index_checked" not in st.session_state:
        if _ollama_is_healthy():
            try:
                st.write("LLM: –∏–Ω–¥–µ–∫—Å–∞—Ü–∏—è –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã‚Ä¶")
                progress_text = st.empty()
                current_line = st.empty()
                bar = st.progress(0)

                def _on_progress(processed: int, total: int | None, info: dict):
                    phase = str(info.get("phase", "") or "")
                    # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: –µ—Å–ª–∏ –æ–±—â–∏–π –æ–±—ä—ë–º –∏–∑–≤–µ—Å—Ç–µ–Ω ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å‚Äë–±–∞—Ä
                    if isinstance(total, int) and total > 0:
                        pct = int(max(0, min(100, processed * 100.0 / total)))
                        bar.progress(pct)
                        progress_text.markdown(f"–≠—Ç–∞–ø: {phase} ‚Ä¢ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed} –∏–∑ {total}")
                    else:
                        # –ï—Å–ª–∏ –æ–±—â–µ–≥–æ –æ–±—ä—ë–º–∞ –Ω–µ—Ç ‚Äî —Ç–æ–ª—å–∫–æ —Å—á—ë—Ç—á–∏–∫ –±–µ–∑ –ø—Ä–æ–≥—Ä–µ—Å—Å‚Äë–±–∞—Ä–∞
                        progress_text.markdown(f"–≠—Ç–∞–ø: {phase} ‚Ä¢ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed}")
                    # –¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è
                    name = str(info.get("name") or info.get("last_name") or "")
                    code = str(info.get("code") or info.get("last_code") or "")
                    article = str(info.get("article") or "")
                    parts = [p for p in [name, article, code] if p]
                    current_line.markdown("–¢–µ–∫—É—â–∞—è –ø–æ–∑–∏—Ü–∏—è: " + (" | ".join(parts) if parts else "‚Äî"))

                ok_idx, idx_msg, skipped = ensure_llama_index_daily(on_progress=_on_progress)

                # –û—á–∏—Å—Ç–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                try:
                    bar.empty()
                    current_line.empty()
                    progress_text.empty()
                except Exception:
                    pass

                if ok_idx and skipped:
                    st.caption(f"LLM: {idx_msg}")
                elif ok_idx:
                    st.success(f"LLM: {idx_msg}")
                else:
                    st.warning(f"LLM: {idx_msg}")
            except Exception as e:
                st.warning(f"LLM: —Å–±–æ–π –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏: {e}")
        st.session_state["llama_index_checked"] = True
     
    # –£–º–µ–Ω—å—à–∞–µ–º —à—Ä–∏—Ñ—Ç—ã –≤ —Å–∞–π–¥–±–∞—Ä–µ
    st.markdown("""
        <style>
        section[data-testid="stSidebar"] {
            font-size: 0.9rem !important;
        }
        section[data-testid="stSidebar"] * {
            font-size: 0.9rem !important;
        }
        section[data-testid="stSidebar"] .stRadio label {
            font-size: 0.9rem !important;
            margin: 0.1rem 0 !important;
            padding: 0 !important;
        }
        /* –ï–¥–∏–Ω—ã–π —Å—Ç–∏–ª—å –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –±–ª–æ–∫–æ–≤ –≤ —Å–∞–π–¥–±–∞—Ä–µ */
        section[data-testid="stSidebar"] h1,
        section[data-testid="stSidebar"] h2,
        section[data-testid="stSidebar"] h3 {
            font-size: 1.1rem !important;   /* –Ω–∞ —à–∞–≥ –±–æ–ª—å—à–µ –±–∞–∑–æ–≤–æ–≥–æ 0.9rem */
            margin: 0.25rem 0 0.5rem 0 !important;
        }
        section[data-testid="stSidebar"] .stDateInput label,
        section[data-testid="stSidebar"] .stNumberInput label,
        section[data-testid="stSidebar"] .stTextInput label,
        section[data-testid="stSidebar"] .stCheckbox label {
            font-size: 0.9rem !important;
        }
        section[data-testid="stSidebar"] .stButton button {
            font-size: 0.9rem !important;
        }
        section[data-testid="stSidebar"] .stSelectbox label {
            font-size: 0.9rem !important;
        }
        </style>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.subheader("–ù–∞–≤–∏–≥–∞—Ü–∏—è")
        try:
            page = st.radio(
                "",
                ["–ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", "–≠—Ç–∞–ø—ã", "–†–µ—Å—É—Ä—Å—ã", "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î"],
                index=0,
                label_visibility="collapsed",
                key="nav_radio",
            )
        except TypeError:
            # Fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π Streamlit –±–µ–∑ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ label_visibility
            page = st.radio(
                "",
                ["–ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", "–≠—Ç–∞–ø—ã", "–†–µ—Å—É—Ä—Å—ã", "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î"],
                index=0,
                key="nav_radio",
            )

        st.divider()
        # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è –≤ —Å–∞–π–¥–±–∞—Ä–µ: –±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ –≤—ã–≥—Ä—É–∑–∫–∏ –æ—Å—Ç–∞—Ç–∫–æ–≤ –∏–∑ 1–° (OData)
        if st.button("–í—ã–≥—Ä—É–∑–∏—Ç—å –æ—Å—Ç–∞—Ç–∫–∏ –∏–∑ 1–°", type="primary", key="btn_sync_odata_quick"):
            from src.database import init_database
            from src.odata_stock_sync import sync_stock_from_odata

            # –ß–∏—Ç–∞–µ–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ config/odata_config.json
            cfg = _load_odata_config()
            base_url = (cfg.get("base_url") or "").strip()
            entity_name = (cfg.get("entity_name") or "").strip()
            username = (cfg.get("username") or "").strip() or None
            password = (cfg.get("password") or "").strip() or None

            # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è base_url: —É–±—Ä–∞—Ç—å –∑–∞–≤–µ—Ä—à–∞—é—â–∏–π $metadata, –µ—Å–ª–∏ –æ—à–∏–±–æ—á–Ω–æ —É–∫–∞–∑–∞–Ω
            if base_url.lower().endswith("$metadata"):
                base_url = base_url[: -len("$metadata")].rstrip("/")

            # –ü–æ–ª—è –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ –æ—Ç–∫–ª—é—á–µ–Ω—ã –Ω–∞ –±—ã—Å—Ç—Ä—ã–π –∑–∞–ø—É—Å–∫ (–∏–∑–±–µ–≥–∞–µ–º $expand –∏ –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –ø—É—Ç–µ–π, –≤–µ–¥—É—â–∏—Ö –∫ 400)
            select_fields = None

            # –í–∞–ª–∏–¥–∞—Ü–∏—è —Å—É—â–Ω–æ—Å—Ç–∏
            if not base_url or not entity_name:
                st.warning("–°–Ω–∞—á–∞–ª–∞ –∑–∞–ø–æ–ª–Ω–∏—Ç–µ –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ ¬´–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î¬ª.")
            elif "$metadata" in entity_name.lower():
                st.error("–í –ø–æ–ª–µ ¬´–°—É—â–Ω–æ—Å—Ç—å/–æ—Å—Ç–∞—Ç–∫–∏ (EntitySet)¬ª —É–∫–∞–∂–∏—Ç–µ –∏–º—è –Ω–∞–±–æ—Ä–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, AccumulationRegister_–ó–∞–ø–∞—Å—ã–ù–∞–°–∫–ª–∞–¥–∞—Ö), –±–µ–∑ ¬´$metadata¬ª.")
            else:
                init_database()
                try:
                    with st.spinner("–í—ã–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞—Ç–∫–æ–≤ –∏–∑ 1–°‚Ä¶"):
                        stats = sync_stock_from_odata(
                            base_url=base_url,
                            entity_name=entity_name,
                            username=username,
                            password=password,
                            token=None,
                            filter_query=None,
                            select_fields=select_fields,
                            db_path=None,
                            dry_run=False,
                            zero_missing=False,  # —è–≤–Ω–æ –Ω–µ –æ–±–Ω—É–ª—è—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –ø–æ–∑–∏—Ü–∏–∏
                        )
                    st.success("–û—Å—Ç–∞—Ç–∫–∏ –∏–∑ 1–° –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –∑–∞–ø–∏—Å–∞–Ω—ã –≤ –ë–î")
                    st.caption(f"–í—Å–µ–≥–æ –ø–æ–∑–∏—Ü–∏–π –≤ –ë–î: {stats.items_total} ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –≤ OData: {stats.matched_in_odata} ‚Ä¢ –û–±–Ω—É–ª–µ–Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö: {stats.unmatched_zeroed}")
                    try:
                        st.json(asdict(stats))
                    except Exception:
                        st.write(stats)
                    st.rerun()
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –æ—Å—Ç–∞—Ç–∫–æ–≤: {e}")

    def compute_df(start: dt.date, days: int) -> pd.DataFrame:
        """
        –ü–æ—Å—Ç—Ä–æ–∏—Ç—å DataFrame –ø–æ —Ç–µ–∫—É—â–µ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∏ —Å—Ä–∞–∑—É –ø–æ–¥—Ç—è–Ω—É—Ç—å —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        –∏–∑ production_plan_entries –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –¥–∞—Ç (stage_id IS NULL).
        """
        days = int(days)
        df = generate_plan_dataframe(db_path=None, horizon_days=days, start_date=start)

        # –ó–∞–ø–æ–ª–Ω–∏–º —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–ª–∞–Ω–∞ –ø–æ –¥–∞—Ç–∞–º
        item_codes = [str(x) for x in df.get("–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è", []) if pd.notna(x)]
        if not item_codes:
            return df

        start_iso = start.isoformat()
        end_iso = (start + dt.timedelta(days=days - 1)).isoformat()
        date_headers = [c for c in df.columns if _is_date_header(c)]
        if not date_headers:
            return df

        with get_connection(None) as conn:
            placeholders = ",".join("?" for _ in item_codes)
            rows = conn.execute(
                f"""
                SELECT i.item_code AS code, p.date AS d, p.planned_qty AS qty
                FROM production_plan_entries p
                JOIN items i ON i.item_id = p.item_id
                WHERE p.stage_id IS NULL
                  AND p.date BETWEEN ? AND ?
                  AND i.item_code IN ({placeholders})
                """,
                [start_iso, end_iso, *item_codes],
            ).fetchall()

        if rows:
            # –ë—ã—Å—Ç—Ä–æ–µ –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫ DataFrame –ø–æ –∞—Ä—Ç–∏–∫—É–ª—É
            index_by_code = {str(code): idx for idx, code in enumerate(df["–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è"].tolist())}
            for r in rows:
                code = str(r["code"])
                try:
                    hdr = dt.datetime.strptime(str(r["d"]), "%Y-%m-%d").strftime("%d.%m.%y")
                except Exception:
                    continue
                if hdr not in date_headers:
                    continue
                row_idx = index_by_code.get(code)
                if row_idx is None:
                    continue
                try:
                    df.at[row_idx, hdr] = float(r["qty"])
                except Exception:
                    pass

            # –ü–µ—Ä–µ—Å—á—ë—Ç "–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü" –ø–æ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–º –¥–Ω–µ–≤–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º
            df_numeric = df.copy()
            for c in date_headers:
                df_numeric[c] = pd.to_numeric(df_numeric[c], errors="coerce").fillna(0.0)
            df["–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü"] = df_numeric[date_headers].sum(axis=1)

        return df

    # –ó–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –¥–∞—Ç/–≥–æ—Ä–∏–∑–æ–Ω—Ç–∞ (–∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ '–≠—Ç–∞–ø—ã' –¥–æ –æ—Ç—Ä–∏—Å–æ–≤–∫–∏ —Ñ–æ—Ä–º—ã)
    start_date = st.session_state.get("plan_start_date", dt.date.today())
    horizon_days = int(st.session_state.get("plan_horizon", 30))

    # –†–µ–∂–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã "–≠—Ç–∞–ø—ã": –æ—Ç–¥–µ–ª—å–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –∫–∞–∫ –≤ Excel, —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –∏–∑–¥–µ–ª–∏–π
    if page == "–≠—Ç–∞–ø—ã":
        _render_stages_page(start_date)
        return
        
    # –†–µ–∂–∏–º —Å—Ç—Ä–∞–Ω–∏—Ü—ã "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î"
    if page == "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î":
        _render_sync_settings_page()
        return

    if page == "–†–µ—Å—É—Ä—Å—ã":
        _render_resources_page()
        return

    st.title("–ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞")
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ "–ü–ª–∞–Ω –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞"
    with st.container():
        # –°—Ç–∞—Ä–∞—Ç—å—Å—è –≤—ã—Ä–æ–≤–Ω—è—Ç—å –∫–Ω–æ–ø–∫—É –ø–æ –Ω–∏–∂–Ω–µ–π –∫—Ä–æ–º–∫–µ –ø–æ–ª–µ–π (Streamlit >= 1.31)
        try:
            col1, col2, col3 = st.columns([2, 2, 1], vertical_alignment="bottom")
            _needs_spacer = False
        except TypeError:
            # Fallback –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π Streamlit –±–µ–∑ vertical_alignment
            col1, col2, col3 = st.columns([2, 2, 1])
            _needs_spacer = True

        with col1:
            start_date = st.date_input("–î–∞—Ç–∞ –Ω–∞—á–∞–ª–∞", value=dt.date.today(), format="DD.MM.YYYY", key="plan_start_date")
        with col2:
            horizon_days = st.number_input(
                "–ì–æ—Ä–∏–∑–æ–Ω—Ç, –¥–Ω–µ–π",
                min_value=7,
                max_value=90,
                value=30,
                step=1,
                key="plan_horizon",
            )
        with col3:
            # –í —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏—è—Ö Streamlit –¥–æ–±–∞–≤–∏–º –Ω–µ–±–æ–ª—å—à–æ–π –æ—Ç—Å—Ç—É–ø —Å–≤–µ—Ä—Ö—É,
            # —á—Ç–æ–±—ã –∫–Ω–æ–ø–∫–∞ –≤–∏–∑—É–∞–ª—å–Ω–æ —Å–æ–≤–ø–∞–¥–∞–ª–∞ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏ —Å –ø–æ–ª—è–º–∏ –≤–≤–æ–¥–∞.
            if _needs_spacer:
                st.markdown('<div style="height: 2.2rem;"></div>', unsafe_allow_html=True)
            recalc = st.button("–ü–µ—Ä–µ—Å—á–∏—Ç–∞—Ç—å", key="plan_recalc")

    # –ü–µ—Ä–µ—Å—á—ë—Ç –∫—ç—à–∞ –ø–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º
    if recalc:
        df = compute_df(start_date, int(horizon_days))
    else:
        df = compute_df(start_date, int(horizon_days))

    # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—ã –≤ –ø–ª–∞–Ω (–ø–æ–∏—Å–∫ —á–µ—Ä–µ–∑ LLM, —Ñ–æ–ª–±—ç–∫ –ë–î)
    with st.container():
        st.subheader("–î–æ–±–∞–≤–∏—Ç—å –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä—É –≤ –ø–ª–∞–Ω")
        q = st.text_input("–ù–∞–∑–≤–∞–Ω–∏–µ –∏–ª–∏ –∞—Ä—Ç–∏–∫—É–ª", key="nom_search_query", placeholder="–ù–∞—á–Ω–∏—Ç–µ –≤–≤–æ–¥–∏—Ç—å –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–ª–∏ –∞—Ä—Ç–∏–∫—É–ª‚Ä¶")
        selected_option = None
        options: list[str] = []
        option_map: dict[str, dict] = {}
        if isinstance(q, str) and len(q.strip()) >= 2:
            q_clean = q.strip()
            results = _llama_search_nomenclature(q_clean, limit=10)
            if not results:
                # –§–æ–ª–±—ç–∫ –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –ë–î
                results = _db_search_nomenclature(q_clean, limit=10)
            for r in results:
                name = str(r.get("name") or r.get("item_name") or "")
                code = str(r.get("code") or r.get("item_code") or "")
                if not code:
                    continue
                label = f"{name}, {code}" if name else code
                if label not in option_map:
                    options.append(label)
                    option_map[label] = {"name": name, "code": code}
            if options:
                selected_option = st.selectbox("–ù–∞–π–¥–µ–Ω–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã", options=options, index=0, key="nom_search_select")
        add_disabled = (selected_option is None)
        add_clicked = st.button("–î–æ–±–∞–≤–∏—Ç—å –≤ –ø–ª–∞–Ω", type="primary", disabled=add_disabled, key="btn_add_to_plan")
        if add_clicked and selected_option:
            sel = option_map.get(selected_option, {})
            name = sel.get("name") or ""
            code = sel.get("code") or ""
            try:
                _ensure_item_and_add_to_roots(code=code, name=name)
                st.success(f"–î–æ–±–∞–≤–ª–µ–Ω–æ –≤ –ø–ª–∞–Ω: {name or ''} [{code}]")
                st.rerun()
            except Exception as e:
                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å –≤ –ø–ª–∞–Ω: {e}")

    # –°–≤–æ–¥–∫–∞ –ø–æ —Ç–∞–±–ª–∏—Ü–µ
    date_cols = [c for c in df.columns if _is_date_header(c)]
    st.caption(f"–°—Ç—Ä–æ–∫: {len(df)} ‚Ä¢ –ö–æ–ª–æ–Ω–æ–∫ –¥–∞—Ç: {len(date_cols)}")

    if df.empty:
        st.info("–í –ë–î –Ω–µ—Ç –∫–æ—Ä–Ω–µ–≤—ã—Ö –∏–∑–¥–µ–ª–∏–π. –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –ø–æ–≤—Ç–æ—Ä–∏—Ç–µ.")
    else:
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ä–µ–¥–∞–∫—Ç–∏—Ä—É–µ–º–æ–π —Ç–∞–±–ª–∏—Ü—ã: —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ -> —á–∏—Å–ª–∞
        date_cols = [c for c in df.columns if _is_date_header(c)]
        df_for_edit = df.copy()
        for col in ("–í—ã–ø–æ–ª–Ω–µ–Ω–æ", "–ù–µ–¥–æ–≤—ã–ø–æ–ª–Ω–µ–Ω–æ"):
            if col in df_for_edit.columns:
                df_for_edit[col] = pd.to_numeric(df_for_edit[col], errors="coerce").fillna(0.0)
        for c in date_cols:
            df_for_edit[c] = pd.to_numeric(df_for_edit[c], errors="coerce").fillna(0.0)

        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∫–æ–ª–æ–Ω–æ–∫
        col_config: dict[str, st.column_config.Column] = {
            "–í—ã–ø–æ–ª–Ω–µ–Ω–æ": st.column_config.NumberColumn("–í—ã–ø–æ–ª–Ω–µ–Ω–æ", format="%.0f", step=1, min_value=0.0),
            "–ù–µ–¥–æ–≤—ã–ø–æ–ª–Ω–µ–Ω–æ": st.column_config.NumberColumn("–ù–µ–¥–æ–≤—ã–ø–æ–ª–Ω–µ–Ω–æ", format="%.0f", step=1, min_value=0.0),
            "–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü": st.column_config.NumberColumn("–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü (—Å—É–º–º–∞ –ø–æ –¥–Ω—è–º)", format="%.0f", disabled=True),
        }
        for c in date_cols:
            d = dt.datetime.strptime(c, "%d.%m.%y").date()
            label = c
            if d.weekday() >= 5:
                # –û—Ç–º–µ—á–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –∫—Ä–∞—Å–Ω–æ–π –º–µ—Ç–∫–æ–π –ø–µ—Ä–µ–¥ –¥–∞—Ç–æ–π
                label = f"üî¥ {c}"
            col_config[c] = st.column_config.NumberColumn(label=label, format="%.0f", step=1, min_value=0.0)

        edited = st.data_editor(
            df_for_edit,
            column_config=col_config,
            width="stretch",
            hide_index=True,
            key="plan_editor",
        )

        # –ü–µ—Ä–µ—Å—á–µ—Ç "–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü" –∏–∑ –≤–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –ø–æ –¥–Ω—è–º
        edited_numeric = edited.copy()
        for c in date_cols:
            edited_numeric[c] = pd.to_numeric(edited_numeric[c], errors="coerce").fillna(0.0)
        edited_numeric["–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü"] = edited_numeric[date_cols].sum(axis=1)

        st.caption("–ü–ª–∞–Ω –Ω–∞ –º–µ—Å—è—Ü –ø–µ—Ä–µ—Å—á–∏—Ç–∞–Ω –∏–∑ –≤–≤–µ–¥—ë–Ω–Ω–æ–≥–æ –ø–ª–∞–Ω–∞ –ø–æ –¥–∞—Ç–∞–º.")

        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø–ª–∞–Ω–∞ –≤ –ë–î (—á–µ—Ä–Ω–æ–≤–∏–∫, stage_id=NULL)
        if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–ª–∞–Ω (—á–µ—Ä–Ω–æ–≤–∏–∫) –≤ –ë–î", type="primary"):
            saved = _save_plan_to_db(edited_numeric, date_cols)
            st.success(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ/–æ–±–Ω–æ–≤–ª–µ–Ω–æ —Å—Ç—Ä–æ–∫: {saved}")

        st.divider()
        st.subheader("–†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å —Å–æ—Å—Ç–∞–≤")
        edit_mode = st.checkbox("–í–∫–ª—é—á–∏—Ç—å —Ä–µ–∂–∏–º —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ—Å—Ç–∞–≤–∞", key="edit_comp_mode")
        if edit_mode:
            # –¢–∞–±–ª–∏—Ü–∞ –≤—ã–±–æ—Ä–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            try:
                select_df = df[["–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è", "–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è"]].copy()
            except Exception:
                select_df = pd.DataFrame(columns=["–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –∏–∑–¥–µ–ª–∏—è", "–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è"])
            select_df.insert(0, "–í—ã–±—Ä–∞—Ç—å", False)
            edited_sel = st.data_editor(
                select_df,
                column_config={
                    "–í—ã–±—Ä–∞—Ç—å": st.column_config.CheckboxColumn("–í—ã–±—Ä–∞—Ç—å"),
                },
                hide_index=True,
                width="stretch",
                key="edit_comp_table",
            )
            # –°–æ–±–∏—Ä–∞–µ–º –≤—ã–±—Ä–∞–Ω–Ω—ã–µ –∞—Ä—Ç–∏–∫—É–ª–∞
            try:
                selected_codes = [
                    str(c) for c, flag in zip(
                        edited_sel.get("–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è", []),
                        edited_sel.get("–í—ã–±—Ä–∞—Ç—å", [])
                    ) if flag
                ]
            except Exception:
                selected_codes = []

            c1, c2 = st.columns([1, 2])
            with c1:
                confirm = st.checkbox("–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é —É–¥–∞–ª–µ–Ω–∏–µ", key="confirm_del_comp")
            with c2:
                del_disabled = not selected_codes
                if st.button(f"–£–¥–∞–ª–∏—Ç—å –≤—ã–±—Ä–∞–Ω–Ω—ã–µ ({len(selected_codes)})", type="secondary", disabled=del_disabled, key="btn_delete_selected"):
                    if not confirm:
                        st.warning("–ü–æ—Å—Ç–∞–≤—å—Ç–µ –≥–∞–ª–æ—á–∫—É ¬´–ü–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é —É–¥–∞–ª–µ–Ω–∏–µ¬ª –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.")
                    else:
                        try:
                            _delete_items_from_plan_by_codes(selected_codes)
                            st.success(f"–£–¥–∞–ª–µ–Ω–æ –ø–æ–∑–∏—Ü–∏–π: {len(selected_codes)}")
                            st.rerun()
                        except Exception as e:
                            st.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è: {e}")


    # –≠–∫—Å–ø–æ—Ä—Ç —Ç–µ–∫—É—â–µ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –≤ CSV (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏/—Å–≤–µ—Ä–∫–∏)
    csv = df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "–°–∫–∞—á–∞—Ç—å CSV-–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ",
        data=csv,
        file_name="production_plan_preview.csv",
        mime="text/csv",
    )


def _save_plan_to_db(df: pd.DataFrame, date_cols: list[str]) -> int:
    """
    –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π –ø–ª–∞–Ω –≤ —Ç–∞–±–ª–∏—Ü—É production_plan_entries.

    –ü—Ä–∞–≤–∏–ª–∞ MVP:
      - –î–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏ (–∞—Ä—Ç–∏–∫—É–ª) –∏ –∫–∞–∂–¥–æ–π –¥–∞—Ç—ã –∑–∞–ø–∏—Å—ã–≤–∞–µ–º planned_qty.
      - stage_id –Ω–µ —É–∫–∞–∑—ã–≤–∞–µ–º (NULL), —Ç.–∫. —ç—Ç–æ –æ–±—â–∏–π –ø–ª–∞–Ω –ø–æ –∏–∑–¥–µ–ª–∏—é.
      - –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å —Å—É—â–µ—Å—Ç–≤—É–µ—Ç (—É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á item_id+stage_id+date), –≤—ã–ø–æ–ª–Ω—è–µ–º UPSERT planned_qty.
      - completed_qty/—Å—Ç–∞—Ç—É—Å –Ω–∞ —ç—Ç–æ–º —ç—Ç–∞–ø–µ –Ω–µ —Ç—Ä–æ–≥–∞–µ–º (–æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å, –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0/GREEN).

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã—Ö/–æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã—Ö –∑–∞–ø–∏—Å–µ–π.
    """
    saved = 0
    # –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ item_code -> item_id
    codes = [str(x) for x in df.get("–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è", []) if pd.notna(x)]
    id_by_code: dict[str, int] = {}

    with get_connection(None) as conn:
        if codes:
            # DISTINCT –∫–æ–¥—ã –Ω–∞ —Å–ª—É—á–∞–π –ø–æ–≤—Ç–æ—Ä–æ–≤
            unique_codes = sorted(set(codes))
            placeholders = ",".join("?" for _ in unique_codes)
            rows = conn.execute(
                f"SELECT item_code, item_id FROM items WHERE item_code IN ({placeholders})",
                unique_codes,
            ).fetchall()
            id_by_code = {str(r[0]): int(r[1]) for r in rows if r and r[0] is not None}

        for _, row in df.iterrows():
            code = str(row.get("–ê—Ä—Ç–∏–∫—É–ª –∏–∑–¥–µ–ª–∏—è") or "")
            item_id = id_by_code.get(code)
            if not item_id:
                # –ù–µ –Ω–∞—à–ª–∏ —Ç–æ–≤–∞—Ä –≤ –ë–î ‚Äî –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                continue

            for col in date_cols:
                try:
                    iso_date = dt.datetime.strptime(col, "%d.%m.%y").date().isoformat()
                except Exception:
                    continue
                # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ —á–∏—Å–ª—É
                val = row.get(col)
                try:
                    qty = float(val) if val is not None and str(val) != "" else 0.0
                except Exception:
                    qty = 0.0

                # UPDATE —Å–Ω–∞—á–∞–ª–∞ (—É—á–∏—Ç—ã–≤–∞–µ–º, —á—Ç–æ stage_id IS NULL –Ω–µ —É—á–∞—Å—Ç–≤—É–µ—Ç –≤ UNIQUE-–∫–æ–Ω—Ñ–ª–∏–∫—Ç–µ –≤ SQLite)
                cur = conn.execute(
                    """
                    UPDATE production_plan_entries
                       SET planned_qty = ?,
                           updated_at  = datetime('now')
                     WHERE item_id = ?
                       AND stage_id IS NULL
                       AND date = ?
                    """,
                    (qty, item_id, iso_date),
                )
                if cur.rowcount == 0:
                    # –ï—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –Ω–µ –±—ã–ª–æ ‚Äî –≤—Å—Ç–∞–≤–ª—è–µ–º –Ω–æ–≤—É—é
                    conn.execute(
                        """
                        INSERT INTO production_plan_entries (item_id, stage_id, date, planned_qty)
                        VALUES (?, NULL, ?, ?)
                        """,
                        (item_id, iso_date, qty),
                    )
                saved += 1

        conn.commit()

    return saved


def _get_stages_order(conn) -> list[str]:
    rows = conn.execute(
        "SELECT stage_name FROM production_stages ORDER BY COALESCE(stage_order, stage_id)"
    ).fetchall()
    names = [str(r[0]) for r in rows if r and r[0]]
    return names

def _get_stages_full(conn) -> list[dict]:
    rows = conn.execute(
        "SELECT stage_id, stage_name FROM production_stages ORDER BY COALESCE(stage_order, stage_id)"
    ).fetchall()
    return [{"stage_id": int(r[0]), "stage_name": str(r[1])} for r in rows]

def _get_areas(conn) -> list:
    return conn.execute(
        "SELECT area_id, area_name, active, planning_offset_days, planning_range_days, capacity_per_day, days_per_week, hours_per_day FROM production_areas ORDER BY area_name"
    ).fetchall()

def _get_area_stage_ids(conn, area_id: int) -> set[int]:
    rows = conn.execute(
        "SELECT stage_id FROM area_stage_map WHERE area_id = ?", (area_id,)
    ).fetchall()
    return {int(r[0]) for r in rows}

def _set_area_stages(conn, area_id: int, stage_ids: set[int]) -> None:
    current = _get_area_stage_ids(conn, area_id)
    to_delete = current - stage_ids
    to_insert = stage_ids - current
    if to_delete:
        placeholders = ",".join("?" for _ in to_delete)
        conn.execute(f"DELETE FROM area_stage_map WHERE area_id = ? AND stage_id IN ({placeholders})", [area_id, *to_delete])
    for sid in to_insert:
        conn.execute(
            "INSERT OR IGNORE INTO area_stage_map (area_id, stage_id) VALUES (?, ?)",
            (area_id, sid),
        )
    # –Ø–≤–Ω–æ —Ñ–∏–∫—Å–∏—Ä—É–µ–º –∏–∑–º–µ–Ω–µ–Ω–∏—è –ø–µ—Ä–µ–¥ –≤–æ–∑–º–æ–∂–Ω—ã–º st.rerun()
    conn.commit()

def _insert_area(conn, name: str) -> None:
    conn.execute(
        "INSERT INTO production_areas (area_name) VALUES (?)",
        (name.strip(),),
    )
    conn.commit()

def _delete_area(conn, area_id: int) -> None:
    conn.execute("DELETE FROM production_areas WHERE area_id = ?", (area_id,))
    conn.commit()

def _update_area(conn, area_id: int, active: bool, offset: int, prange: int, capacity: float, days_week: int, hours_day: float) -> None:
    conn.execute(
        """
        UPDATE production_areas
           SET active = ?,
               planning_offset_days = ?,
               planning_range_days = ?,
               capacity_per_day = ?,
               days_per_week = ?,
               hours_per_day = ?,
               updated_at = datetime('now')
         WHERE area_id = ?
        """,
        (1 if active else 0, int(offset), int(prange), float(capacity), int(days_week), float(hours_day), int(area_id)),
    )
    conn.commit()

def _render_resources_page() -> None:
    st.title("–†–µ—Å—É—Ä—Å—ã")
    # –ü–æ–∫–∞–∂–µ–º —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ –æ–± —É—Å–ø–µ—à–Ω–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏ –ø–æ—Å–ª–µ rerun (flash)
    _notice = st.session_state.pop("resources_notice", None)
    if _notice:
        st.success(_notice)

    # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º —Å—Ö–µ–º—É –ë–î (–Ω–∞ —Å–ª—É—á–∞–π —Å—Ç–∞—Ä–æ–π –±–∞–∑—ã –±–µ–∑ –Ω–æ–≤—ã—Ö —Ç–∞–±–ª–∏—Ü —Ä–µ—Å—É—Ä—Å–æ–≤)
    try:
        init_database()
    except Exception:
        pass
    with get_connection(None) as conn:
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –Ω–æ–≤–æ–≥–æ —É—á–∞—Å—Ç–∫–∞
        st.subheader("–î–æ–±–∞–≤–∏—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω—ã–π —É—á–∞—Å—Ç–æ–∫")
        with st.form("add_area_form"):
            new_name = st.text_input("–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —É—á–∞—Å—Ç–∫–∞", key="new_area_name", placeholder="–ù–∞–ø—Ä–∏–º–µ—Ä: –°–±–æ—Ä–æ—á–Ω—ã–π —É—á–∞—Å—Ç–æ–∫ ‚Ññ1")
            submitted = st.form_submit_button("–î–æ–±–∞–≤–∏—Ç—å —É—á–∞—Å—Ç–æ–∫", type="primary")
            if submitted:
                if new_name and new_name.strip():
                    name = new_name.strip()
                    try:
                        # –ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç –ø–æ —Ç–æ—á–Ω–æ–º—É —Å–æ–≤–ø–∞–¥–µ–Ω–∏—é –∏–º–µ–Ω–∏
                        try:
                            exists = conn.execute("SELECT 1 FROM production_areas WHERE area_name = ?", (name,)).fetchone()
                        except sqlite3.OperationalError:
                            # –°–æ–∑–¥–∞—ë–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Ç–∞–±–ª–∏—Ü—ã –∏ –ø–æ–≤—Ç–æ—Ä—è–µ–º –∑–∞–ø—Ä–æ—Å
                            init_database()
                            exists = conn.execute("SELECT 1 FROM production_areas WHERE area_name = ?", (name,)).fetchone()
                        if exists:
                            st.warning(f"–£—á–∞—Å—Ç–æ–∫ —Å –∏–º–µ–Ω–µ–º '{name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
                        else:
                            try:
                                _insert_area(conn, name)
                                st.success(f"–î–æ–±–∞–≤–ª–µ–Ω —É—á–∞—Å—Ç–æ–∫: {name}")
                                st.rerun()
                            except sqlite3.IntegrityError:
                                st.warning(f"–£—á–∞—Å—Ç–æ–∫ —Å –∏–º–µ–Ω–µ–º '{name}' —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç.")
                            except Exception as e:
                                st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å —É—á–∞—Å—Ç–æ–∫: {e}")
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è —É—á–∞—Å—Ç–∫–∞: {e}")
                else:
                    st.warning("–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ —É—á–∞—Å—Ç–∫–∞.")

        st.divider()

        # –°–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–∫–æ–≤
        try:
            areas = _get_areas(conn)
        except sqlite3.OperationalError:
            # –¢–∞–±–ª–∏—Ü—ã –º–æ–≥–ª–∏ –µ—â—ë –Ω–µ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞—Ç—å –≤ —Å—Ç–∞—Ä–æ–π –ë–î ‚Äî —Å–æ–∑–¥–∞—ë–º –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
            init_database()
            areas = _get_areas(conn)
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —É—á–∞—Å—Ç–∫–æ–≤: {e}")
            areas = []

        if not areas:
            st.info("–£—á–∞—Å—Ç–∫–æ–≤ –ø–æ–∫–∞ –Ω–µ—Ç. –î–æ–±–∞–≤—å—Ç–µ –ø–µ—Ä–≤—ã–π —É—á–∞—Å—Ç–æ–∫.")
            return

        # –ü–æ–¥—Ç—è–Ω–µ–º —ç—Ç–∞–ø—ã
        stages = _get_stages_full(conn)
        stage_names = [s["stage_name"] for s in stages]
        id_by_name = {s["stage_name"]: s["stage_id"] for s in stages}
        name_by_id = {s["stage_id"]: s["stage_name"] for s in stages}

        for row in areas:
            area_id = int(row["area_id"])
            area_name = str(row["area_name"])
            active = bool(row["active"])
            offset = int(row["planning_offset_days"])
            prange = int(row["planning_range_days"])
            capacity = float(row["capacity_per_day"])
            days_week = int(row["days_per_week"])
            hours_day = float(row["hours_per_day"])

            with st.expander(f"{area_name} (ID: {area_id})", expanded=False):
                top_cols = st.columns([1,1])
                with top_cols[0]:
                    if st.button("–£–¥–∞–ª–∏—Ç—å —É—á–∞—Å—Ç–æ–∫", key=f"del_area_{area_id}"):
                        _delete_area(conn, area_id)
                        st.success(f"–£—á–∞—Å—Ç–æ–∫ '{area_name}' —É–¥–∞–ª—ë–Ω")
                        st.rerun()
                with top_cols[1]:
                    active_val = st.checkbox(
                        "–£—á–∞—Å—Ç–≤—É–µ—Ç –≤ —Ä–∞—Å—á—ë—Ç–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
                        value=active,
                        key=f"area_active_{area_id}"
                    )

                # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —ç—Ç–∞–ø–æ–≤ (–º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –≤—ã–±–æ—Ä)
                # –í–µ—Ä—Å–∏–æ–Ω–∏—Ä—É–µ–º –∫–ª—é—á –≤–∏–¥–∂–µ—Ç–∞, —á—Ç–æ–±—ã –ø–æ—Å–ª–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è/–æ—á–∏—Å—Ç–∫–∏ –æ–Ω –ø–µ—Ä–µ—á–∏—Ç—ã–≤–∞–ª default –∏–∑ –ë–î
                ver_key = f"area_stages_ver_{area_id}"
                if ver_key not in st.session_state:
                    st.session_state[ver_key] = 0
                ver = st.session_state[ver_key]

                selected_ids = _get_area_stage_ids(conn, area_id)
                selected_names = [name_by_id.get(sid, "") for sid in sorted(selected_ids) if sid in name_by_id]
                selected = st.multiselect(
                    "–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å —ç—Ç–∞–ø–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞ (–º–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ)",
                    options=stage_names,
                    default=selected_names,
                    key=f"area_stages_{area_id}_{ver}",
                    help="–ú–æ–∂–Ω–æ –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç—Ç–∞–ø–æ–≤. –í—ã–±–æ—Ä —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –ø–æ—Å–ª–µ –Ω–∞–∂–∞—Ç–∏—è ¬´–°–æ—Ö—Ä–∞–Ω–∏—Ç—å¬ª."
                )

                # –û—Ç–æ–±—Ä–∞–∂–∞–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –ë–î (–≤–∏–¥–Ω–æ, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ)
                cur_ids = _get_area_stage_ids(conn, area_id)
                cur_names = [name_by_id.get(sid, str(sid)) for sid in sorted(cur_ids)]
                st.caption(f"–ü—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã (–∏–∑ –ë–î): {', '.join(cur_names) if cur_names else '‚Äî'}")

                # –û—á–∏—Å—Ç–∏—Ç—å –≤—Å–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è
                if st.button("–û—á–∏—Å—Ç–∏—Ç—å –≤—ã–±–æ—Ä", key=f"btn_clear_stages_{area_id}"):
                    try:
                        _set_area_stages(conn, area_id, set())
                        # –û—Ç–æ–±—Ä–∞–∑–∏–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –∏–∑ –ë–î –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
                        cur_ids_after = _get_area_stage_ids(conn, area_id)
                        cur_names_after = [name_by_id.get(sid, str(sid)) for sid in sorted(cur_ids_after)]
                        st.success("–°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è —ç—Ç–∞–ø–æ–≤ –æ—á–∏—â–µ–Ω—ã")
                        st.caption(f"–ü—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã (–∏–∑ –ë–î): {', '.join(cur_names_after) if cur_names_after else '‚Äî'}")
                    except Exception as e:
                        st.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ—á–∏—Å—Ç–∏—Ç—å —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è: {e}")

                # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è
                c1, c2, c3 = st.columns(3)
                with c1:
                    offset_val = st.number_input("–°–¥–≤–∏–≥ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –¥–Ω–µ–π", min_value=0, max_value=365, step=1, value=offset, key=f"area_offset_{area_id}")
                with c2:
                    range_val = st.number_input("–î–∏–∞–ø–∞–∑–æ–Ω –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è, –¥–Ω–µ–π", min_value=1, max_value=365, step=1, value=prange, key=f"area_range_{area_id}")
                with c3:
                    capacity_val = st.number_input("–ú–æ—â–Ω–æ—Å—Ç—å, –µ–¥./–¥–µ–Ω—å", min_value=0.0, step=1.0, value=capacity, key=f"area_capacity_{area_id}")

                c4, c5 = st.columns(2)
                with c4:
                    days_week_val = st.number_input("–î–Ω–µ–π –≤ –Ω–µ–¥–µ–ª—é", min_value=1, max_value=7, step=1, value=days_week, key=f"area_days_week_{area_id}")
                with c5:
                    hours_day_val = st.number_input("–ß–∞—Å–æ–≤ –≤ –¥–µ–Ω—å", min_value=0.0, max_value=24.0, step=0.5, value=hours_day, key=f"area_hours_day_{area_id}")

                if st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å", type="primary", key=f"save_area_{area_id}"):
                    try:
                        _update_area(conn, area_id, active_val, int(offset_val), int(range_val), float(capacity_val), int(days_week_val), float(hours_day_val))
                        sel_ids = {id_by_name.get(n) for n in selected if n in id_by_name}
                        sel_ids = {sid for sid in sel_ids if sid is not None}
                        _set_area_stages(conn, area_id, sel_ids)
                        # –ü–æ–∫–∞–∂–µ–º —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–µ –ø—Ä–∏–≤—è–∑–∫–∏
                        cur_ids_after = _get_area_stage_ids(conn, area_id)
                        cur_names_after = [name_by_id.get(sid, str(sid)) for sid in sorted(cur_ids_after)]
                        st.success(f"–ò–∑–º–µ–Ω–µ–Ω–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã. –ü—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ —ç—Ç–∞–ø—ã: {', '.join(cur_names_after) if cur_names_after else '‚Äî'}")
                        st.caption(f"(–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î –¥–ª—è —É—á–∞—Å—Ç–∫–∞ '{area_name}')")
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")




def _render_stages_page(start_date: dt.date) -> None:
    """
    –°—Ç—Ä–∞–Ω–∏—Ü–∞ '–≠—Ç–∞–ø—ã' ‚Äî –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–∞–∫ –≤ Excel:
      - –í—ã–ø–∞–¥–∞—é—â–∏–π —Å–ø–∏—Å–æ–∫ —ç—Ç–∞–ø–æ–≤
      - –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–æ—Ä–Ω–µ–≤–æ–≥–æ –∏–∑–¥–µ–ª–∏—è ‚Äî –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–∞–±–ª–∏—Ü–∞ –µ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ
      - –ö–æ–ª–æ–Ω–∫–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç Excel-–ª–∏—Å—Ç–∞–º —ç—Ç–∞–ø–æ–≤ (—Å–º. –æ–±—Ä–∞–∑–µ—Ü)
    """
    st.title("–≠—Ç–∞–ø—ã (–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∫–∞–∫ –≤ Excel)")
    with get_connection(None) as conn:
        stage_names = _get_stages_order(conn)
        selected_stage = st.selectbox("–≠—Ç–∞–ø", options=stage_names, index=0, key="stages_select")

        # –û—Å—Ç–∞—Ç–∫–∏ –ø–æ –≤—Å–µ–º –∞—Ä—Ç–∏–∫—É–ª–∞–º (–¥–ª—è –∫–æ–ª–æ–Ω–∫–∏ '–û—Å—Ç–∞—Ç–æ–∫ –Ω–∞ ‚Ä¶')
        stock_rows = conn.execute("SELECT item_code, COALESCE(stock_qty, 0.0) AS qty FROM items").fetchall()
        stock_by_code = {str(r[0]): float(r[1]) for r in stock_rows}

        # –ö–æ—Ä–Ω–µ–≤—ã–µ –∏–∑–¥–µ–ª–∏—è
        roots_df = get_root_products(conn)

        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ —Ç–∞–±–ª–∏—Ü—ã –∫–∞–∫ –≤ Excel
        date_str = start_date.strftime("%d.%m.%Y")
        is_purchase = selected_stage in ("–ó–∞–∫—É–ø–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏", "–ó–∞–∫—É–ø–∫–∞")
        if is_purchase:
            headers = [
                "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ",
                "–ê—Ä—Ç–∏–∫—É–ª",
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –æ–¥–Ω–æ –∏–∑–¥–µ–ª–∏–µ",
                f"–û—Å—Ç–∞—Ç–æ–∫ –Ω–∞ {date_str}",
                "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è –∑–∞–∫–∞–∑–∞",
                "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è –∑–∞–∫–∞–∑–∞",
                "–ó–∞–∫–∞–∑–∞–Ω–æ",
                "–°—Ä–æ–∫ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è (–¥–Ω–∏)",
            ]
        else:
            headers = [
                "–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–Ω–æ–µ –Ω–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –¥–µ—Ç–∞–ª–∏/–∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞",
                "–ê—Ä—Ç–∏–∫—É–ª –¥–µ—Ç–∞–ª–∏",
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –æ–¥–Ω–æ –∏–∑–¥–µ–ª–∏–µ",
                f"–û—Å—Ç–∞—Ç–æ–∫ –Ω–∞ {date_str}",
                "–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è –∑–∞–∫–∞–∑–∞",
                "–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è –∑–∞–∫–∞–∑–∞",
                "–í—Ä–µ–º—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è (–¥–Ω–∏)",
                "–í –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ",
            ]

        # –ü–æ –∫–∞–∂–¥–æ–º—É –∫–æ—Ä–Ω–µ–≤–æ–º—É –∏–∑–¥–µ–ª–∏—é –≤—ã–≤–æ–¥–∏–º –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ —Ç–∞–±–ª–∏—Ü—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–≥–æ —ç—Ç–∞–ø–∞
        for _, root in roots_df.iterrows():
            root_code = str(root.get("item_code") or "")
            root_name = str(root.get("item_name") or "")
            if not root_code:
                continue

            st.markdown(f"### {root_name} [{root_code}]")

            try:
                bom_df = explode_bom_for_root(conn, root_code=root_code, order_qty=1.0, max_depth=15)
            except Exception:
                bom_df = None

            if bom_df is None or bom_df.empty:
                st.info("–ù–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ç–æ–≥–æ –∏–∑–¥–µ–ª–∏—è.")
                continue

            stage_filter = "–ó–∞–∫—É–ø–∫–∞" if is_purchase else selected_stage
            stage_df = bom_df[bom_df["stage_name"] == stage_filter].copy()
            if stage_df.empty:
                st.caption("–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —ç—Ç–∞–ø–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
                continue

            stage_df = stage_df.sort_values(["item_code"])
            rows_out = []
            for _, comp in stage_df.iterrows():
                name_v = str(comp.get("item_name") or "")
                code_v = str(comp.get("item_code") or "")
                qty_per_unit = float(comp.get("required_qty") or 0.0)
                stock_val = float(stock_by_code.get(code_v, 0.0))

                if is_purchase:
                    row = [
                        name_v,
                        code_v,
                        qty_per_unit,
                        stock_val,
                        "",  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è
                        "",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è
                        "",  # –ó–∞–∫–∞–∑–∞–Ω–æ
                        "",  # –°—Ä–æ–∫ –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è (–¥–Ω–∏)
                    ]
                else:
                    row = [
                        name_v,
                        code_v,
                        qty_per_unit,
                        stock_val,
                        "",  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è
                        "",  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø–∞—Ä—Ç–∏—è
                        "",  # –í—Ä–µ–º—è –ø–æ–ø–æ–ª–Ω–µ–Ω–∏—è (–¥–Ω–∏)
                        "",  # –í –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–æ
                    ]
                rows_out.append(row)

            df_stage = pd.DataFrame(rows_out, columns=headers)
            st.dataframe(df_stage, width="stretch", hide_index=True)


def _render_sync_settings_page() -> None:
    """
    –°—Ç—Ä–∞–Ω–∏—Ü–∞ '–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î':
      - URL OData —Å–µ—Ä–≤–∏—Å–∞
      - Login
      - Password
      - –°—É—â–Ω–æ—Å—Ç—å/–æ—Å—Ç–∞—Ç–∫–∏ (EntitySet)
      - –ü–æ–ª—è –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ ($select, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)
    –ö–Ω–æ–ø–∫–∏:
      - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
      - –í—ã–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ ($metadata ‚Üí output/odata_metadata.xml –∏ summary JSON)
      - –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ ($metadata)
    –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ config/odata_config.json.
    """
    st.title("–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏ –ë–î")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—É—â–∏–π –∫–æ–Ω—Ñ–∏–≥ (—Ç–æ–ª–µ—Ä–∞–Ω—Ç–µ–Ω –∫ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—é —Ñ–∞–π–ª–∞/–∫–ª—é—á–µ–π)
    cfg = _load_odata_config()

    # –ü–æ–ª—è –≤–≤–æ–¥–∞
    base_url = st.text_input(
        "URL OData —Å–µ—Ä–≤–∏—Å–∞ 1–°",
        value=str(cfg.get("base_url", "")),
        help="–ù–∞–ø—Ä–∏–º–µ—Ä: http://mtzw7/unf_demo/odata/standard.odata"
    )

    c1, c2 = st.columns(2)
    with c1:
        username = st.text_input(
            "Login",
            value=str(cfg.get("username", "") or "")
        )
    with c2:
        password = st.text_input(
            "Password",
            value=str(cfg.get("password", "") or ""),
            type="password"
        )

    entity_name = st.text_input(
        "–°—É—â–Ω–æ—Å—Ç—å/–æ—Å—Ç–∞—Ç–∫–∏ (EntitySet)",
        value=str(cfg.get("entity_name", "") or ""),
        help="–ù–∞–ø—Ä–∏–º–µ—Ä: AccumulationRegister_–ó–∞–ø–∞—Å—ã–ù–∞–°–∫–ª–∞–¥–∞—Ö"
    )

    select_fields = st.text_input(
        "–ü–æ–ª—è –¥–ª—è –≤—ã–±–æ—Ä–∫–∏ ($select, —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)",
        value=str(cfg.get("select_fields", "") or ""),
        help="–ù–∞–ø—Ä–∏–º–µ—Ä: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ,–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞/–ö–æ–¥,–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞/Description"
    )

    # –ö–Ω–æ–ø–∫–∏ –¥–µ–π—Å—Ç–≤–∏–π
    b1, b2, b3 = st.columns([1, 1, 1])
    with b1:
        save_click = st.button("–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏", type="primary", key="btn_odata_save")
    with b2:
        fetch_md_click = st.button("–í—ã–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ", key="btn_odata_fetch_md")
    with b3:
        test_click = st.button("–¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ", key="btn_odata_test")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞: –°–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    if save_click:
        new_cfg = {
            "base_url": (base_url or "").strip(),
            "username": (username or "").strip(),
            "password": password or "",
            "entity_name": (entity_name or "").strip(),
            "select_fields": (select_fields or "").strip(),
        }
        _save_odata_config(new_cfg)

        # –î—É–±–ª–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–µ –ø–æ–ª—è –≤ session_state –¥–ª—è —Å–∞–π–¥–±–∞—Ä–∞
        st.session_state.odata_url = new_cfg["base_url"]
        st.session_state.odata_entity = new_cfg["entity_name"]
        st.session_state.odata_username = new_cfg["username"]
        st.session_state.odata_password = new_cfg["password"]
        st.session_state.odata_filter = ""  # –∫–æ–Ω—Ü–µ–ø—Ç—É–∞–ª—å–Ω–æ —É–±—Ä–∞–Ω–æ, –æ–±–Ω—É–ª–∏–º –µ—Å–ª–∏ –±—ã–ª–æ

        st.success("–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ config/odata_config.json")
        st.rerun()

    # –û–±—Ä–∞–±–æ—Ç–∫–∞: –í—ã–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    if fetch_md_click:
        if not base_url:
            st.warning("–£–∫–∞–∂–∏—Ç–µ URL OData —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è –≤—ã–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
        else:
            try:
                import sys, subprocess
                out_xml = "output/odata_metadata.xml"
                out_json = "output/odata_metadata_summary.json"
                cmd = [
                    sys.executable,
                    "scripts/fetch_odata_metadata.py",
                    "--url", base_url,
                    "--out", out_xml,
                    "--summary-out", out_json,
                ]
                # –ü–µ—Ä–µ–¥–∞—ë–º –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é (Basic), –µ—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞
                if username:
                    cmd += ["--username", username]
                if username and password:
                    cmd += ["--password", password]
                # –í—ã–ø–æ–ª–Ω—è–µ–º
                res = subprocess.run(cmd, capture_output=True, text=True)
                if res.returncode == 0:
                    st.success("–ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –≤—ã–≥—Ä—É–∂–µ–Ω—ã")
                    if res.stdout:
                        st.text(res.stdout.strip()[:4000])
                    st.caption(f"XML: {out_xml} ‚Ä¢ Summary: {out_json}")
                else:
                    st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö")
                    st.code(res.stderr or res.stdout or "no stderr/stdout", language="text")
            except Exception as e:
                st.error(f"–°–±–æ–π –ø—Ä–∏ –≤—ã–≥—Ä—É–∑–∫–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")

    # –û–±—Ä–∞–±–æ—Ç–∫–∞: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ ($metadata)
    if test_click:
        if not base_url:
            st.warning("–£–∫–∞–∂–∏—Ç–µ URL OData —Å–µ—Ä–≤–∏—Å–∞ –¥–ª—è —Ç–µ—Å—Ç–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è")
        else:
            try:
                from src.odata_client import OData1CClient
                client = OData1CClient(
                    base_url=base_url,
                    username=username if username else None,
                    password=password if username and password else None,
                    token=None,
                )
                resp = client._make_request("$metadata")
                # –ü–æ–∫–∞–∂–µ–º –∫—Ä–∞—Ç–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç: —Ç–∏–ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –∏ —Ä–∞–∑–º–µ—Ä
                if isinstance(resp, dict) and "_raw" in resp:
                    raw = str(resp.get("_raw", ""))
                    ctype = str(resp.get("_content_type", ""))
                    st.success("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ. –ü–æ–ª—É—á–µ–Ω –Ω–µ-JSON –æ—Ç–≤–µ—Ç (–æ–∂–∏–¥–∞–µ–º–æ –¥–ª—è $metadata).")
                    st.caption(f"Content-Type: {ctype or 'unknown'} ‚Ä¢ size: {len(raw)} bytes")
                else:
                    # –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–µ—Ä–≤–µ—Ä–∞ –º–æ–≥—É—Ç –≤–µ—Ä–Ω—É—Ç—å JSON-–æ–±—ë—Ä—Ç–∫—É
                    st.success("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ. –û—Ç–≤–µ—Ç —Ä–∞–∑–æ–±—Ä–∞–Ω –∫–∞–∫ JSON.")
                    try:
                        st.json(resp)
                    except Exception:
                        st.write(resp)
            except Exception as e:
                st.error(f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)}")

    st.subheader("–¢–µ–∫—É—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
    st.json({
        "base_url": base_url,
        "username": username,
        "password": _mask_secret(password),
        "entity_name": entity_name,
        "select_fields": select_fields,
        "config_path": str(CONFIG_PATH),
    })


if __name__ == "__main__":
    main()